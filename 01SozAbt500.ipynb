{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#General stuff\n",
    "import time\n",
    "import datetime\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import progressbar\n",
    "import jellyfish\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from collections import Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling in all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/df_final_harm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I want to look for repetitions \"sozialrechtliche Abteilungen\"\n",
    "And I'm working with the years, as the whole long string consisting of 15'000 verdicts is just too long. The Kernel dies regularly. Which really isn't much fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sozrecht = df[df['recht_harm'] == 'Sozialrecht']\n",
    "sozrecht = df_sozrecht[df_sozrecht['Language'] == 'De']['Text-Nummer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting up the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(sozrecht)\n",
    "n = 1000\n",
    "txt_lsts = [l[i:i + n] for i in range(0, len(l), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25% (4 of 16) |######                     | Elapsed Time: 0:02:54 ETA: 0:08:43"
     ]
    }
   ],
   "source": [
    "df_ = pd.DataFrame(columns=['index', 0])\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for txt_lst, i in zip(txt_lsts, bar(range(len(txt_lsts)))):\n",
    "\n",
    "    long_str = ''\n",
    "    \n",
    "    for txt in txt_lst:\n",
    "    \n",
    "        file = open('txt_files/' + txt, 'r')\n",
    "        text = file.read()\n",
    "        #Making sure the line breaks '/n', 'xa0' and double spaces are removed\n",
    "        text = text.replace('\\n', ' ').replace('\\xa0', '').replace('  ', ' ')\n",
    "        #Removing these automated notifications\n",
    "        text = text.replace('Wichtiger Hinweis:Diese Website wird in älteren Versionen von Netscape ohne graphische Elemente dargestellt. Die Funktionalität der Website ist aber trotzdem gewährleistet. Wenn Sie diese Website regelmässig benutzen, empfehlen wir Ihnen, auf Ihrem Computer einen aktuellen Browser zu installieren.Zurück zur Einstiegsseite Drucken Grössere Schrift', '')\n",
    "        text = text.replace('Vorwärts ähnliche Leitentscheide suchenähnliche Urteile ab 2000 suchen Drucken nach oben', '')\n",
    "        text = text.replace('Bundesgericht Tribunal fédéral Tribunale federale Tribunal federal', '')\n",
    "        text = text.replace('Navigation Neue Suche Zurück zum Suchresultat Rang: Zurück 180', '')\n",
    "        text = text.replace('Navigation Neue Suche Zurück zum Suchresultat Rang:1 ähnliche Leitentscheide suchenähnliche Urteile ab 2000 suchen Drucken nach oben', '')\n",
    "    \n",
    "        long_str = long_str + text\n",
    "        \n",
    "    df_new = pd.DataFrame(pd.Series( long_str[ix:ix+500] for ix in list(range(len(long_str))) ).value_counts()).reset_index()\n",
    "    df_new = df_new[df_new[0]> 1]\n",
    "    \n",
    "    frames = [df_, df_new]\n",
    "    df_ = pd.concat(frames)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving off the result\n",
    "Later, I can just jump to this step, I don't need to repeat the steps above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_.to_csv('500Characters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ = pd.read_csv('500Characters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.columns = [['String', 'Count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_.drop_duplicates(subset='String', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_[df_['Count'] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching similar Strings\n",
    "Using Jellyfish and remodelling the original df, using it to create a new list of string. Because these ones are the ones I don't need to consider anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(columns=['String', 'Count', 'Jaro'])\n",
    "\n",
    "for count in range(1000):\n",
    "    \n",
    "    print(count)\n",
    "    string_list = list(df['String'])\n",
    "    value_list = []\n",
    "    bar = progressbar.ProgressBar()\n",
    "\n",
    "    for elem, i in zip(string_list, bar(range(len(string_list)))):\n",
    "    \n",
    "        value = jellyfish.jaro_distance(string_list[0], elem)\n",
    "        value_list.append(value)\n",
    "    \n",
    "    df['Jaro'] = value_list\n",
    "    df_unique = df[df['Jaro'] >= .825].head(1)\n",
    "\n",
    "    frames = [df_new, df_unique]\n",
    "    df_new = pd.concat(frames)\n",
    "\n",
    "    df = df[df['Jaro'] <= .825]\n",
    "    del df['Jaro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the New DF and Creating a String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_new['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_new['Jaro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(df_new['String']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = list(df_new['String'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating through all the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to pull out relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REGEXES_SCHREIBER = [\n",
    "    r'[gG]reffier\\s*:*\\s*\\w*\\.*\\s*\\w*',\n",
    "    r'[Gg]reffière\\s*:*\\s*\\w*\\.*\\s*\\w*',\n",
    "    r'[gG]erichtsschr eiberi*n*\\s*:* \\w*\\.*\\s*\\w*',\n",
    "    r'[Cc]ancelliere*n*\\s*:* \\w*\\.*\\s*\\w*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gerichtsschreiber(doc):\n",
    "    try:\n",
    "        text = next(chain.from_iterable(re.finditer(r, doc) for r in REGEXES_SCHREIBER), None)\n",
    "        return text.group()\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extracting_date(doc):\n",
    "    Datum = re.findall(r\"[0-9]+\\.[0-9]+\\.20[0-9]+\", doc)\n",
    "    try:\n",
    "        return Datum[0]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extracting_akten_nummer(doc):\n",
    "    an = re.findall(r\"[0-9]*[A-Z][.]*[_]*[ ]*[0-9]+/[0-9]+\", doc)\n",
    "    try:\n",
    "        an = an[0]\n",
    "        an = an.replace('_', ' ')\n",
    "        return an\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(sozrecht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_elems = []\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for text_file, i in zip(l, bar((range(len(l))))):\n",
    "    \n",
    "    file = open('txt_files/' + text_file, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    #Special formatting\n",
    "    text = text.replace('\\n', ' ').replace('\\xa0', '').replace('  ', '')\n",
    "    text = text.replace('  ', ' ')\n",
    "    \n",
    "    Datum = extracting_date(text)\n",
    "    Aktennummer = extracting_akten_nummer(text)\n",
    "    Gerichtsschreiber = gerichtsschreiber(text)\n",
    "    \n",
    "    \n",
    "    if string_list[0] in text:\n",
    "        boolean = 1\n",
    "    else:\n",
    "        boolean = 0\n",
    "    \n",
    "    mini_dict = {'Text Nummer': text_file,\n",
    "                 'Datum': Datum,\n",
    "                 string_list[0][:20]: boolean,\n",
    "                 'Aktennummer': Aktennummer,\n",
    "                 'Gerichtsschreiber': Gerichtsschreiber}\n",
    "    \n",
    "    txt_elems.append(mini_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bools = pd.DataFrame(txt_elems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat what I did above, now attaching the lists to df_bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for string, i in zip(string_list, bar(range(len(string_list)))):\n",
    "    \n",
    "    bool_list = []\n",
    "    \n",
    "    for text_file in l:\n",
    "    \n",
    "        file = open('txt_files/' + text_file, 'r')\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "    \n",
    "        #Special formatting\n",
    "        text = text.replace('\\n', ' ').replace('\\xa0', '').replace('  ', '')\n",
    "        text = text.replace('  ', ' ')\n",
    "    \n",
    "        if string in text:\n",
    "            boolean = 1\n",
    "        else:\n",
    "            boolean = 0\n",
    "        \n",
    "        bool_list.append(boolean)\n",
    "    \n",
    "    df_bools[string[:20]] = bool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bools.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bools.to_csv('bools900text_snippets_de_soz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bools = pd.read_csv('bools900text_snippets_de_soz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_bools['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bools['Gerichtsschreiber'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Total Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bools['TOTAL'] = df_bools.sum(axis=1, numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bools['TOTAL'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bools['Datetime'] = pd.to_datetime(df_bools['Datum'], format=\"%d.%m.%Y\")\n",
    "df_bools.index = df_bools['Datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_pyear = pd.DataFrame(df_bools.resample('A')['TOTAL'].sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change(elem):\n",
    "    elem = str(elem)\n",
    "    elem = int(elem.replace('-12-31 00:00:00', ''))\n",
    "    return elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_pyear['Years'] = df_counts_pyear['Datetime'].apply(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = smf.ols(formula=\"TOTAL~Years\",data=df_counts_pyear).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intercept, slope = lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_pyear.plot(x=\"Years\",y=\"TOTAL\")\n",
    "plt.plot(df_counts_pyear[\"Years\"],slope*df_counts_pyear[\"Years\"]+intercept,\"-\",color=\"red\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
